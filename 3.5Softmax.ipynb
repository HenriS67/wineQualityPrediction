{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n",
      "0               7.4             0.700         0.00             1.9      0.076  \\\n",
      "1               7.8             0.880         0.00             2.6      0.098   \n",
      "2               7.8             0.760         0.04             2.3      0.092   \n",
      "3              11.2             0.280         0.56             1.9      0.075   \n",
      "4               7.4             0.700         0.00             1.9      0.076   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "1138            6.3             0.510         0.13             2.3      0.076   \n",
      "1139            6.8             0.620         0.08             1.9      0.068   \n",
      "1140            6.2             0.600         0.08             2.0      0.090   \n",
      "1141            5.9             0.550         0.10             2.2      0.062   \n",
      "1142            5.9             0.645         0.12             2.0      0.075   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates   \n",
      "0                    11.0                  34.0  0.99780  3.51       0.56  \\\n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
      "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
      "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
      "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
      "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
      "\n",
      "      alcohol  quality    Id  \n",
      "0         9.4        5     0  \n",
      "1         9.8        5     1  \n",
      "2         9.8        5     2  \n",
      "3         9.8        6     3  \n",
      "4         9.4        5     4  \n",
      "...       ...      ...   ...  \n",
      "1138     11.0        6  1592  \n",
      "1139      9.5        6  1593  \n",
      "1140     10.5        5  1594  \n",
      "1141     11.2        6  1595  \n",
      "1142     10.2        5  1597  \n",
      "\n",
      "[1143 rows x 13 columns]\n",
      "[[ 0.93933222 -0.96338181 -0.57365783 -1.36502663]\n",
      " [ 1.94181282 -0.59360107  0.1308811  -1.36502663]\n",
      " [ 1.27349242 -0.59360107 -0.04525363 -1.16156762]\n",
      " ...\n",
      " [ 0.38239855  0.05351522 -0.45623467 -0.9581086 ]\n",
      " [ 0.10393172  0.70063152  0.60057372 -0.8563791 ]\n",
      " [ 0.6330187  -0.22382033  0.30701583 -0.75464959]]\n",
      "[5 7 7 5 5 7 5 6 6 7 4 5 4 6 6 5 5 6 5 5 5 6 5 4 5 6 4 5 5 6 6 5 4 5 6 6 5\n",
      " 5 5 5 5 5 6 5 5 7 5 5 5 4 5 5 5 4 6 5 5 4 4 6 5 6 5 5 5 5 5 6 6 4 7 7 7 5\n",
      " 6 6 6 7 6 6 7 7 6 6 5 5 5 5 7 5 4 5 5 4 8 6 6 8 7 7 7 5 6 7 7 5 5 6 7 7 6\n",
      " 5 7 7 6 7 6 6 5 6 7 7 5 5 7 7 7 6 6 7 6 6 8 6 5 7 6 7 4 7 5 6 5 5 7 5 7 7\n",
      " 6 6 7 5 6 5 8 7 7 5 5 6 6 6 7 8 3 6 5 6 5 6 5 8 5 6 7 7 6 8 6 8 6 7 7 7 7\n",
      " 7 7 6 6 7 7 5 3 6 5 6 5 6 7 5 6 6 6 6 6 6 6 5 5 5 5 6 4 5 5 6 7 8 6 5 5 5\n",
      " 6 6 6 5 6 5 6 5 5 5 5 4 5 5 5 4 7 6 5 7 5 6 5 5 5 5 5 6 6 4 4 5 5 5 5 5 5\n",
      " 5 6 5 5 5 5 5 6 5 5 6 5 6 6 5 6 6 5 6 5 5 5 6 6 5 7 7 6 7 5 6 5 4 7 5 7 4\n",
      " 6 4 7 7 7 5 5 5 6 7 7 4 7 6 5 6 7 6 7 7 7 7 6 6 6 5 6 6 7 4 7 6 5 7 7 7 7\n",
      " 7 7 7 7 7 7 7 6 5 5 7 7 6 6 5 6 6 7 5 7 7 7 7 7 6 5 7 6 7 7 5 6 7 7 7 6 6\n",
      " 6 6 6 6 7 7 5 7 7 6 8 6 6 7 7 7 7 7 5 7 6 7 7 8 7 6 6 6 7 5 7 6 8 7 6 5 7\n",
      " 7 7 6 6 6 6 6 5 7 6 6 5 7 7 7 5 7 6 6 6 4 4 7 6 6 6 6 6 7 8 5 7 7 7 7 6 6\n",
      " 6 6 6 7 5 5 6 4 4 5 6 5 4 6 6 6 6 4 6 7 6 6 5 5 5 3 5 5 6 6 6 6 6 5 5 5 6\n",
      " 6 6 6 6 5 6 5 6 6 5 5 5 5 5 5 6 6 5 8 6 6 7 6 5 7 5 5 5 6 4 5 5 7 6 5 5 6\n",
      " 5 5 8 7 7 7 6 7 6 4 7 4 7 3 5 7 7 3 4 5 5 5 5 5 7 6 5 6 6 3 6 5 6 6 6 5 6\n",
      " 7 5 6 7 6 5 8 7 6 5 5 5 5 6 5 5 6 6 6 6 7 6 6 6 5 5]\n",
      "[[ 0.71655875 -0.96338181 -0.57365783 -1.36502663]\n",
      " [ 0.66086539 -0.4087107  -1.10206203 -1.36502663]\n",
      " [ 0.27101182 -0.87093663 -0.51494625 -1.26329712]\n",
      " ...\n",
      " [-0.11884175  0.51574115  0.54186214 -0.70378484]\n",
      " [ 0.38239855  0.05351522 -0.45623467 -0.9581086 ]\n",
      " [ 0.6330187  -0.22382033  0.30701583 -0.75464959]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('WineQT.csv')\n",
    "print(df)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# load the dataset\n",
    "\n",
    "y_train = df['quality']\n",
    "X_train= [df['volatile acidity'],df['alcohol'],df['sulphates'],df['citric acid']]\n",
    "X_features = ['volatile acidity','alcohol','sulphates','citric acid']\n",
    "X_train=np.transpose(np.asmatrix(X_train))\n",
    "y_train=np.asarray(y_train)\n",
    "\n",
    "\n",
    "def zscore_normalize_features(X):\n",
    "    mu     = np.mean(X, axis=0)                 # mu will have shape (n,)\n",
    "    # find the standard deviation of each column/feature\n",
    "    sigma  = np.std(X, axis=0)                  # sigma will have shape (n,)\n",
    "    # element-wise, subtract mu for that column from each example, divide by std for that column\n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return (X_norm, mu, sigma)\n",
    "\n",
    "X_norm, X_mu, X_sigma = zscore_normalize_features(X_train)\n",
    "print(X_norm)\n",
    "import random\n",
    "fig,ax=plt.subplots(1,2,sharey=True)\n",
    "ax[0].hist(df[\"quality\"], bins='auto',label=\"quality\")\n",
    "ax[0].set_title(\"quality before modif\")\n",
    "supp=[]\n",
    "#on supprime aleatoirement des valeurs de notes 5 et 6 (diviser par 3)\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==5 or y_train[i]==6:\n",
    "        rand=random.random()\n",
    "        if(rand>0.4):\n",
    "            supp.append(i)\n",
    "for j in range(len(supp)):\n",
    "    y_train2=np.delete(y_train,supp)\n",
    "    X_norm2=np.delete(X_norm,supp,0)\n",
    "\n",
    "\n",
    "ax[1].hist(y_train2, bins='auto',label=\"quality\")\n",
    "ax[1].set_title(\"quality after modif\")\n",
    "\n",
    "print(y_train2)\n",
    "print(X_norm2)\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test =train_test_split(wine_df.drop('quality',axis=1), wine_df['quality'], test_size=.3,\n",
    " #                                                  random_state=22)\n",
    "#X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Args:\n",
    "        z (ndarray): A scalar, numpy array of any size.\n",
    "\n",
    "    Returns:\n",
    "        g (ndarray): sigmoid(z), with the same shape as z\n",
    "         \n",
    "    \"\"\"\n",
    "\n",
    "    g = 1/(1+np.exp(-z))\n",
    "   \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "\n",
    "\n",
    "def compute_cost_softmax(X, y, W, B):\n",
    "    m, n = X.shape\n",
    "    #print(\"n\",n)\n",
    "    nb_f=W.shape[0]\n",
    "    #print(\"nf\",nb_f)\n",
    "   ### START CODE HERE ###\n",
    "    loss_sum = 0 \n",
    "\n",
    "    \n",
    "  # on calcule tous les zj=fwb\n",
    "   # Loop over each training example\n",
    "    for i in range(m): \n",
    "      f_WB=np.zeros(nb_f)\n",
    "      # Loop over each class\n",
    "      for loop in range(nb_f):\n",
    "        z_wb = 0 \n",
    "       # Loop over each feature\n",
    "        for j in range(n): \n",
    "\n",
    "             z_wb_ij = W[loop,j]*X[i,j]\n",
    "             z_wb += z_wb_ij \n",
    "        z_wb += B[loop] \n",
    "\n",
    "        f_WB[loop] = sigmoid(z_wb)#=e(Zij), #à diviser par sumezi pour avoir probabilité que y==loop\n",
    "\n",
    "      sumEzi=sum(f_WB)\n",
    "      \n",
    "      loss_sum += np.log(f_WB[y[i]]/sumEzi) # on ajoute -log(a_i) if y=i\n",
    "\n",
    "    total_cost = -(1 / m) * loss_sum  \n",
    "\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "def compute_gradient_softmax(X, y, W, B): \n",
    "\n",
    "\n",
    "    m, n = X.shape\n",
    "    nb_f=W.shape[0]\n",
    "\n",
    "    dJ_DW = np.zeros((nb_f,n))                           #(n,)\n",
    "    dJ_DB = np.zeros((nb_f))\n",
    "\n",
    "    for i in range(m): \n",
    "      f_WB=np.zeros(nb_f)\n",
    "      # Loop over each class\n",
    "      for loop in range(nb_f):\n",
    "        z_wb = 0 \n",
    "       # Loop over each feature\n",
    "        for j in range(n): \n",
    "\n",
    "             z_wb_ij = W[loop,j]*X[i,j]\n",
    "             z_wb += z_wb_ij \n",
    "        z_wb += B[loop] \n",
    "\n",
    "        f_WB[loop] = sigmoid(z_wb)#=e(Zij)\n",
    "\n",
    "      sumEzi=sum(f_WB) \n",
    "      f_WB=f_WB/sumEzi # tableau des probabilité que y==loop\n",
    "\n",
    "      #on calcule la dérivé\n",
    "      for loop in range(nb_f):\n",
    "        err_loop  = f_WB[loop]  - (y[loop]==y[i])         #scalar, proba que y = loop  - (1 ou 0)(si y ==loop)\n",
    "        for j in range(n):\n",
    "            dJ_DW[loop,j] = dJ_DW[loop,j] + err_loop * X[i,j]      #scalar\n",
    "        dJ_DB[loop] = dJ_DB[loop] + err_loop\n",
    "      dJ_DW = dJ_DW/m                                   #(n,)\n",
    "      dJ_DB = dJ_DB/m                                   #scalar\n",
    "        \n",
    "    return dJ_DB, dJ_DW \n",
    "\n",
    "def gradient_descent_softmax(X, y, W_in, B_in, alpha, num_iters): \n",
    "\n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    W = copy.deepcopy(W_in)  #avoid modifying global w within function\n",
    "    B = B_in\n",
    "    m, n = X.shape\n",
    "    nb_f=W.shape[0]\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dJ_DB, dJ_DW = compute_gradient_softmax(X, y, W, B)   \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        W = W - alpha * dJ_DW               \n",
    "        B = B - alpha * dJ_DB               \n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( compute_cost_softmax(X, y, W, B) )\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            \n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]}   \")\n",
    "            print(\"W : \",W,\" B : \",B)\n",
    "            x_test = X_train[50]   # negative example\n",
    "            print(x_test)\n",
    "            tabProbas=np.dot(W,x_test)+B\n",
    "            print(tabProbas)\n",
    "            \n",
    "    return W, B, J_history         #return final w,b and J history for graphing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_feature(X1, X2):\n",
    "    X1 = np.atleast_1d(X1)\n",
    "    X2 = np.atleast_1d(X2)\n",
    "    degree = 6\n",
    "    out = []\n",
    "    for i in range(1, degree+1):\n",
    "        for j in range(i + 1):\n",
    "            out.append((X1**(i-j) * (X2**j)))\n",
    "    return np.stack(out, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test cout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[-0.082978    0.22032449 -0.49988563 -0.19766743]\n",
      " [-0.35324411 -0.40766141 -0.31373979 -0.15443927]\n",
      " [-0.10323253  0.03881673 -0.08080549  0.1852195 ]\n",
      " [-0.29554775  0.37811744 -0.47261241  0.17046751]\n",
      " [-0.0826952   0.05868983 -0.35961306 -0.30189851]\n",
      " [ 0.30074457  0.46826158 -0.18657582  0.19232262]\n",
      " [ 0.37638915  0.39460666 -0.41495579 -0.46094522]\n",
      " [-0.33016958  0.3781425  -0.40165317 -0.07889237]\n",
      " [ 0.45788953  0.03316528  0.19187711 -0.18448437]]\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      " cost : 2.2211481414984697\n"
     ]
    }
   ],
   "source": [
    "#[df['volatile acidity'],df['alcohol'],df['sulphates'],df['citric acid']]\n",
    "X_train=np.copy(X_norm2)\n",
    "y_train=np.copy(y_train2)\n",
    "nbClasses=9\n",
    "print(X_train.shape[1])\n",
    "\n",
    "np.random.seed(1)\n",
    "initial_W = np.random.rand(nbClasses,X_train.shape[1]) - 0.5\n",
    "print(initial_W)\n",
    "initial_B = np.ones(nbClasses)*0.5\n",
    "print(initial_B)\n",
    "cost = compute_cost_softmax(X_train, y_train, initial_W, initial_B)\n",
    "\n",
    "print(\" cost :\", cost)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71655875 -0.96338181 -0.57365783 -1.36502663]\n",
      " [ 0.66086539 -0.4087107  -1.10206203 -1.36502663]\n",
      " [ 0.27101182 -0.87093663 -0.51494625 -1.26329712]\n",
      " ...\n",
      " [-0.11884175  0.51574115  0.54186214 -0.70378484]\n",
      " [ 0.38239855  0.05351522 -0.45623467 -0.9581086 ]\n",
      " [ 0.6330187  -0.22382033  0.30701583 -0.75464959]]\n",
      "initial_W :\n",
      " [[-0.082978    0.22032449 -0.49988563 -0.19766743]\n",
      " [-0.35324411 -0.40766141 -0.31373979 -0.15443927]\n",
      " [-0.10323253  0.03881673 -0.08080549  0.1852195 ]\n",
      " [-0.29554775  0.37811744 -0.47261241  0.17046751]\n",
      " [-0.0826952   0.05868983 -0.35961306 -0.30189851]\n",
      " [ 0.30074457  0.46826158 -0.18657582  0.19232262]\n",
      " [ 0.37638915  0.39460666 -0.41495579 -0.46094522]\n",
      " [-0.33016958  0.3781425  -0.40165317 -0.07889237]\n",
      " [ 0.45788953  0.03316528  0.19187711 -0.18448437]]\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "dj_db: [-0.00153495  0.0001887   0.00017893 -0.00156933 -0.00152313  0.00018833\n",
      " -0.00150089  0.00016967  0.00023027]\n",
      "First few elements of dj_dw:\n",
      " [[-9.70997604e-04  3.42828683e-04 -4.69259184e-04  1.15888126e-03]\n",
      " [ 1.19368526e-04 -4.21450386e-05  5.76883794e-05 -1.42466162e-04]\n",
      " [ 1.13191635e-04 -3.99678540e-05  5.47157933e-05 -1.35084266e-04]\n",
      " [-9.92747579e-04  3.50509899e-04 -4.79777251e-04  1.18483446e-03]\n",
      " [-9.63515950e-04  3.40183873e-04 -4.65632314e-04  1.14996066e-03]\n",
      " [ 1.19137616e-04 -4.20653586e-05  5.75831649e-05 -1.42185636e-04]\n",
      " [-9.49443487e-04  3.35214615e-04 -4.58828901e-04  1.13316716e-03]\n",
      " [ 1.07324291e-04 -3.78884915e-05  5.18425599e-05 -1.28104482e-04]\n",
      " [ 1.45685515e-04 -5.14497736e-05  7.04399852e-05 -1.73842791e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "\n",
    "np.random.seed(1)\n",
    "initial_W = np.random.rand(nbClasses,X_train.shape[1]) - 0.5\n",
    "print(\"initial_W :\\n\",initial_W)\n",
    "initial_B = np.ones(nbClasses)*0.5\n",
    "print(initial_B)\n",
    " \n",
    "lambda_ = 0.5\n",
    "dJ_DB, dJ_DW = compute_gradient_softmax(X_train, y_train, initial_W, initial_B)\n",
    "\n",
    "print(f\"dj_db: {dJ_DB}\", )\n",
    "print(f\"First few elements of dj_dw:\\n {dJ_DW}\", )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRADIENT DESCENT APPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_W :\n",
      " [[-0.082978    0.22032449 -0.49988563 -0.19766743]\n",
      " [-0.35324411 -0.40766141 -0.31373979 -0.15443927]\n",
      " [-0.10323253  0.03881673 -0.08080549  0.1852195 ]\n",
      " [-0.29554775  0.37811744 -0.47261241  0.17046751]\n",
      " [-0.0826952   0.05868983 -0.35961306 -0.30189851]\n",
      " [ 0.30074457  0.46826158 -0.18657582  0.19232262]\n",
      " [ 0.37638915  0.39460666 -0.41495579 -0.46094522]\n",
      " [-0.33016958  0.3781425  -0.40165317 -0.07889237]\n",
      " [ 0.45788953  0.03316528  0.19187711 -0.18448437]]\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "Iteration    0: Cost 2.2211489036436802   \n",
      "W :  [[-0.0828809   0.22029021 -0.4998387  -0.19778332]\n",
      " [-0.35325605 -0.40765719 -0.31374556 -0.15442503]\n",
      " [-0.10324384  0.03882073 -0.08081096  0.18523301]\n",
      " [-0.29544848  0.37808239 -0.47256443  0.17034903]\n",
      " [-0.08259885  0.05865581 -0.3595665  -0.30201351]\n",
      " [ 0.30073265  0.46826578 -0.18658158  0.19233683]\n",
      " [ 0.3764841   0.39457314 -0.41490991 -0.46105853]\n",
      " [-0.33018031  0.37814629 -0.40165835 -0.07887956]\n",
      " [ 0.45787496  0.03317043  0.19187007 -0.18446698]]  B :  [0.5001535  0.49998113 0.49998211 0.50015693 0.50015231 0.49998117\n",
      " 0.50015009 0.49998303 0.49997697]\n",
      "Iteration  100: Cost 2.2212362376940225   \n",
      "W :  [[-0.07317596  0.2168637  -0.49514855 -0.20936611]\n",
      " [-0.35444596 -0.40723707 -0.31432062 -0.15300486]\n",
      " [-0.10437217  0.03921914 -0.08135638  0.18657957]\n",
      " [-0.28552706  0.37457943 -0.46776959  0.15850791]\n",
      " [-0.07296821  0.05525557 -0.35491236 -0.31350772]\n",
      " [ 0.29954504  0.46868511 -0.18715559  0.1937542 ]\n",
      " [ 0.38597522  0.39122217 -0.41032322 -0.47238626]\n",
      " [-0.33125014  0.37852397 -0.40217512 -0.0776026 ]\n",
      " [ 0.4564225   0.03368338  0.1911678  -0.1827338 ]]  B :  [0.51549503 0.49810011 0.49819853 0.51584064 0.51537647 0.49810382\n",
      " 0.51515371 0.49829177 0.4976812 ]\n",
      "Iteration  200: Cost 2.221344850296483   \n",
      "W :  [[-0.0634809   0.21344069 -0.49046317 -0.22093713]\n",
      " [-0.3556285  -0.40681956 -0.31489211 -0.1515935 ]\n",
      " [-0.10549346  0.03961506 -0.08189839  0.18791773]\n",
      " [-0.27561758  0.37108069 -0.46298052  0.14668104]\n",
      " [-0.0633464   0.05185844 -0.3502625  -0.3249914 ]\n",
      " [ 0.29836479  0.46910183 -0.18772604  0.19516278]\n",
      " [ 0.39545992  0.38787346 -0.40573964 -0.48370631]\n",
      " [-0.33231328  0.37889929 -0.40268866 -0.07633361]\n",
      " [ 0.45497864  0.03419328  0.19046968 -0.18101087]]  B :  [0.53082095 0.49623075 0.49642606 0.53150547 0.53058667 0.49623812\n",
      " 0.53014718 0.49661108 0.49539902]\n",
      "Iteration  300: Cost 2.2214736572362197   \n",
      "W :  [[-0.05379555  0.2100211  -0.4857825  -0.23249656]\n",
      " [-0.35680378 -0.40640461 -0.31546009 -0.1501908 ]\n",
      " [-0.10660783  0.04000855 -0.08243706  0.18924764]\n",
      " [-0.26571996  0.36758613 -0.45819719  0.13486832]\n",
      " [-0.05373324  0.04846438 -0.34561682 -0.33646476]\n",
      " [ 0.29719179  0.46951599 -0.18829298  0.19656272]\n",
      " [ 0.40493837  0.38452696 -0.40115909 -0.49501891]\n",
      " [-0.33336983  0.37927228 -0.40319902 -0.07507247]\n",
      " [ 0.45354324  0.0347002   0.18977567 -0.17929804]]  B :  [0.54613154 0.49437285 0.49466453 0.54715158 0.5457832  0.49438387\n",
      " 0.54513078 0.49494079 0.49313021]\n",
      "Iteration  400: Cost 2.221621601791534   \n",
      "W :  [[-0.04411974  0.20660488 -0.48110644 -0.24404462]\n",
      " [-0.35797193 -0.40599218 -0.31602462 -0.1487966 ]\n",
      " [-0.10771541  0.04039963 -0.08297244  0.19056945]\n",
      " [-0.25583409  0.36409573 -0.45341954  0.12306961]\n",
      " [-0.04412855  0.0450733  -0.34097524 -0.34792801]\n",
      " [ 0.29602591  0.46992764 -0.18885648  0.19795416]\n",
      " [ 0.41441076  0.3811826  -0.39658147 -0.50632428]\n",
      " [-0.33441993  0.37964299 -0.40370624 -0.07381904]\n",
      " [ 0.45211616  0.03520418  0.18908567 -0.17759513]]  B :  [0.56142704 0.49252623 0.49291374 0.5627791  0.56096634 0.49254087\n",
      " 0.5601048  0.49328071 0.49087455]\n",
      "Iteration  500: Cost 2.2217876546600763   \n",
      "W :  [[-0.03445331  0.20319198 -0.47643492 -0.25558148]\n",
      " [-0.35913307 -0.40558222 -0.31658575 -0.14741077]\n",
      " [-0.1088163   0.04078835 -0.08350459  0.19188328]\n",
      " [-0.24595987  0.36060944 -0.44864754  0.11128481]\n",
      " [-0.03453216  0.04168516 -0.33633767 -0.35938137]\n",
      " [ 0.29486702  0.47033682 -0.18941659  0.19933725]\n",
      " [ 0.42387726  0.37784032 -0.3920067  -0.51762264]\n",
      " [-0.33546368  0.38001145 -0.4042104  -0.07257319]\n",
      " [ 0.45069725  0.03570527  0.18839964 -0.17590198]]  B :  [0.57670773 0.49069069 0.4911735  0.5783882  0.57613638 0.49070892\n",
      " 0.57506951 0.49163067 0.48863181]\n",
      "Iteration  600: Cost 2.2219708139055605   \n",
      "W :  [[-0.02479609  0.19978233 -0.47176785 -0.26710736]\n",
      " [-0.36028732 -0.4051747  -0.31714356 -0.14603315]\n",
      " [-0.10991064  0.04117475 -0.08403357  0.19318929]\n",
      " [-0.23609721  0.35712723 -0.44388112  0.0995138 ]\n",
      " [-0.02494388  0.03829988 -0.33170403 -0.37082504]\n",
      " [ 0.29371501  0.47074357 -0.18997337  0.20071215]\n",
      " [ 0.43333805  0.37450006 -0.38743469 -0.52891417]\n",
      " [-0.33650118  0.38037772 -0.40471154 -0.07133479]\n",
      " [ 0.44928638  0.03620353  0.18771749 -0.17421841]]  B :  [0.59197386 0.48886603 0.48944364 0.59397905 0.59129358 0.48888784\n",
      " 0.5900252  0.48999049 0.48640177]\n",
      "Iteration  700: Cost 2.2221701049360267   \n",
      "W :  [[-0.01514791  0.19637587 -0.46710517 -0.27862244]\n",
      " [-0.36143482 -0.40476957 -0.31769809 -0.1446636 ]\n",
      " [-0.11099853  0.04155888 -0.08455942  0.19448761]\n",
      " [-0.226246    0.35364907 -0.43912024  0.08775645]\n",
      " [-0.01536355  0.03491741 -0.32707423 -0.38225923]\n",
      " [ 0.29256975  0.47114793 -0.19052689  0.20207899]\n",
      " [ 0.4427933   0.37116176 -0.38286537 -0.5401991 ]\n",
      " [-0.33753256  0.38074181 -0.40520971 -0.07010369]\n",
      " [ 0.4478834   0.03669899  0.18703916 -0.17254425]]  B :  [0.60722569 0.48705205 0.48772396 0.60955179 0.60643822 0.48707744\n",
      " 0.60497214 0.48836    0.4841842 ]\n",
      "Iteration  800: Cost 2.222384580520207   \n",
      "W :  [[-0.00550861  0.19297255 -0.46244678 -0.29012694]\n",
      " [-0.36257567 -0.40436678 -0.31824941 -0.14330198]\n",
      " [-0.11208009  0.04194077 -0.08508221  0.19577837]\n",
      " [-0.21640613  0.35017491 -0.43436484  0.07601263]\n",
      " [-0.00579099  0.03153768 -0.3224482  -0.39368414]\n",
      " [ 0.29143112  0.47154995 -0.1910772   0.20343791]\n",
      " [ 0.45224318  0.36782536 -0.37829865 -0.55147761]\n",
      " [-0.33855792  0.38110379 -0.40570498 -0.06887978]\n",
      " [ 0.44648817  0.03719172  0.18636459 -0.17087935]]  B :  [0.62246349 0.48524858 0.48601429 0.62510662 0.62157058 0.48527751\n",
      " 0.61991057 0.48673901 0.48197888]\n",
      "Iteration  900: Cost 2.2226133208447623   \n",
      "W :  [[ 0.00412197  0.18957231 -0.4577926  -0.30162103]\n",
      " [-0.36370999 -0.4039663  -0.31879758 -0.14194813]\n",
      " [-0.11315544  0.04232047 -0.085602    0.19706173]\n",
      " [-0.20657748  0.34670472 -0.42961488  0.0642822 ]\n",
      " [ 0.00377396  0.02816064 -0.31782584 -0.40509999]\n",
      " [ 0.290299    0.47194968 -0.19162437  0.20478907]\n",
      " [ 0.46168783  0.36449079 -0.37373445 -0.56274989]\n",
      " [-0.33957738  0.38146367 -0.40619738 -0.06766291]\n",
      " [ 0.44510056  0.03768176  0.18569369 -0.16922353]]  B :  [0.63768752 0.48345541 0.48431443 0.64064371 0.63669092 0.48348787\n",
      " 0.63484075 0.48512736 0.4797856 ]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "initial_W = np.random.rand(nbClasses,X_train.shape[1]) - 0.5\n",
    "print(\"initial_W :\\n\",initial_W)\n",
    "initial_B = np.ones(nbClasses)*0.5\n",
    "print(initial_B)\n",
    "\n",
    "# Some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 0.1\n",
    "\n",
    "W,B, J_history = gradient_descent_softmax(X_train, y_train, initial_W, initial_B, alpha, iterations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.38239855 -0.31626552 -0.69108098 -1.21243237]\n",
      "[1.2917431  0.86099134 0.24451885 0.70194347 1.37019182 0.32581853\n",
      " 1.66648269 0.59418196 0.71056154]\n"
     ]
    }
   ],
   "source": [
    "x_test = X_train[50]   # negative example\n",
    "print(x_test)\n",
    "\n",
    "tabProbas=np.dot(W,x_test)+B\n",
    "print(tabProbas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
