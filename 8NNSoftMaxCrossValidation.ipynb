{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n",
      "0               7.4             0.700         0.00             1.9      0.076  \\\n",
      "1               7.8             0.880         0.00             2.6      0.098   \n",
      "2               7.8             0.760         0.04             2.3      0.092   \n",
      "3              11.2             0.280         0.56             1.9      0.075   \n",
      "4               7.4             0.700         0.00             1.9      0.076   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "1138            6.3             0.510         0.13             2.3      0.076   \n",
      "1139            6.8             0.620         0.08             1.9      0.068   \n",
      "1140            6.2             0.600         0.08             2.0      0.090   \n",
      "1141            5.9             0.550         0.10             2.2      0.062   \n",
      "1142            5.9             0.645         0.12             2.0      0.075   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates   \n",
      "0                    11.0                  34.0  0.99780  3.51       0.56  \\\n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
      "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
      "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
      "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
      "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
      "\n",
      "      alcohol  quality    Id  \n",
      "0         9.4        5     0  \n",
      "1         9.8        5     1  \n",
      "2         9.8        5     2  \n",
      "3         9.8        6     3  \n",
      "4         9.4        5     4  \n",
      "...       ...      ...   ...  \n",
      "1138     11.0        6  1592  \n",
      "1139      9.5        6  1593  \n",
      "1140     10.5        5  1594  \n",
      "1141     11.2        6  1595  \n",
      "1142     10.2        5  1597  \n",
      "\n",
      "[1143 rows x 13 columns]\n",
      "[[ 0.93933222 -0.96338181 -0.57365783 -1.36502663]\n",
      " [ 1.94181282 -0.59360107  0.1308811  -1.36502663]\n",
      " [ 1.27349242 -0.59360107 -0.04525363 -1.16156762]\n",
      " ...\n",
      " [ 0.38239855  0.05351522 -0.45623467 -0.9581086 ]\n",
      " [ 0.10393172  0.70063152  0.60057372 -0.8563791 ]\n",
      " [ 0.6330187  -0.22382033  0.30701583 -0.75464959]]\n",
      "(590,)\n",
      "(590, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('WineQT.csv')\n",
    "print(df)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# load the dataset\n",
    "\n",
    "y_train = df['quality']\n",
    "X_train= [df['volatile acidity'],df['alcohol'],df['sulphates'],df['citric acid']]\n",
    "X_features = ['volatile acidity','alcohol','sulphates','citric acid']\n",
    "X_train=np.transpose(np.asmatrix(X_train))\n",
    "y_train=np.asarray(y_train)\n",
    "\n",
    "\n",
    "def zscore_normalize_features(X):\n",
    "    mu     = np.mean(X, axis=0)                 # mu will have shape (n,)\n",
    "    # find the standard deviation of each column/feature\n",
    "    sigma  = np.std(X, axis=0)                  # sigma will have shape (n,)\n",
    "    # element-wise, subtract mu for that column from each example, divide by std for that column\n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return (X_norm, mu, sigma)\n",
    "\n",
    "X_norm, X_mu, X_sigma = zscore_normalize_features(X_train)\n",
    "print(X_norm)\n",
    "import random\n",
    "fig,ax=plt.subplots(1,2,sharey=True)\n",
    "ax[0].hist(df[\"quality\"], bins='auto',label=\"quality\")\n",
    "ax[0].set_title(\"quality before modif\")\n",
    "supp=[]\n",
    "#on supprime aleatoirement des valeurs de notes 5 et 6 (diviser par 3)\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==5 or y_train[i]==6:\n",
    "        rand=random.random()\n",
    "        if(rand>0.4):\n",
    "            supp.append(i)\n",
    "for j in range(len(supp)):\n",
    "    y_train2=np.delete(y_train,supp)\n",
    "    X_norm2=np.delete(X_norm,supp,0)\n",
    "\n",
    "\n",
    "ax[1].hist(y_train2, bins='auto',label=\"quality\")\n",
    "ax[1].set_title(\"quality after modif\")\n",
    "\n",
    "print(y_train2.shape)\n",
    "print(X_norm2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIVISION DU JEU DE DONNEES EN TRAIN SET, CROSS VALIDATION ET TEST SET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590, 4)\n",
      "(590,)\n",
      "(354, 4) (118, 4) (118, 4)\n",
      "(354,) (118,) (118,)\n"
     ]
    }
   ],
   "source": [
    "print(X_norm2.shape)\n",
    "print(y_train2.shape)\n",
    "\n",
    "debutcv=int(X_norm2.shape[0]*0.6)\n",
    "debuttest=int(X_norm2.shape[0]*0.8)\n",
    "\n",
    "X_train=X_norm2[0:debutcv]\n",
    "X_cv=X_norm2[debutcv:debuttest]\n",
    "X_test=X_norm2[debuttest:]\n",
    "\n",
    "y_train=y_train2[0:debutcv]\n",
    "y_cv=y_train2[debutcv:debuttest]\n",
    "y_test=y_train2[debuttest:]\n",
    "\n",
    "print(X_train.shape,X_cv.shape,X_test.shape)\n",
    "print(y_train.shape,y_cv.shape,y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation de 3 modèles à comparer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from matplotlib.widgets import Slider\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    tf.random.set_seed(20)\n",
    "    model_1 = Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(4,)),\n",
    "            Dense(25, activation = 'relu'),\n",
    "            Dense(15, activation = 'relu'),\n",
    "            Dense(9, activation = 'softmax')\n",
    "        ],\n",
    "        name='model_1'\n",
    "    )\n",
    "    model_2 = Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(4,)),\n",
    "            Dense(20, activation = 'relu'),\n",
    "            Dense(12, activation = 'relu'),\n",
    "            Dense(12, activation = 'relu'),\n",
    "            Dense(20, activation = 'relu'),\n",
    "            Dense(9, activation = 'softmax')\n",
    "        ],\n",
    "        name='model_2'\n",
    "    )\n",
    "    model_3 = Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(4,)),\n",
    "            Dense(32, activation = 'relu'),\n",
    "            Dense(16, activation = 'relu'),\n",
    "            Dense(8, activation = 'relu'),\n",
    "            Dense(4, activation = 'relu'),\n",
    "            Dense(12, activation = 'relu'),\n",
    "            Dense(9, activation = 'softmax')\n",
    "        ],\n",
    "        name='model_3'\n",
    "    )\n",
    "    \n",
    "    model_list = [model_1, model_2, model_3]\n",
    "\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locateMax(tab):\n",
    "    max=0\n",
    "    for loop in range(len(tab)):\n",
    "        if tab[loop]>tab[max]:\n",
    "            max=loop\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y,yp):\n",
    "    m=len(y)\n",
    "    sum=0\n",
    "    for loop in range(m):\n",
    "        if(yp[loop] == y[loop]):\n",
    "            sum+=1\n",
    "    return((sum/m)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model_1...\n",
      "Done!\n",
      "\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[5. 5. 5. 5. 6. 5. 7. 5. 5. 5. 5. 5. 5. 5. 7. 5. 5. 4. 5. 6. 5. 5. 5. 6.\n",
      " 5. 7. 5. 4. 5. 6. 5. 5. 5. 5. 5. 4. 5. 6. 6. 5. 5. 5. 6. 5. 6. 6. 6. 5.\n",
      " 5. 6. 5. 5. 4. 5. 6. 5. 5. 6. 4. 6. 5. 5. 5. 5. 6. 6. 5. 5. 5. 5. 5. 5.\n",
      " 6. 6. 4. 6. 7. 7. 5. 5. 5. 5. 5. 6. 6. 5. 5. 7. 7. 7. 6. 6. 6. 5. 5. 5.\n",
      " 7. 4. 4. 8. 7. 8. 6. 7. 6. 5. 5. 7. 5. 7. 6. 6. 6. 6. 5. 5. 5. 5. 6. 6.\n",
      " 7. 5. 7. 7. 6. 6. 5. 7. 7. 5. 5. 7. 7. 5. 7. 6. 6. 7. 6. 6. 8. 5. 7. 5.\n",
      " 6. 5. 5. 6. 5. 6. 7. 5. 7. 5. 5. 5. 7. 5. 7. 7. 7. 6. 8. 7. 7. 6. 6. 7.\n",
      " 5. 8. 5. 3. 6. 6. 6. 5. 5. 8. 5. 6. 7. 7. 6. 8. 6. 8. 7. 7. 6. 7. 6. 7.\n",
      " 6. 6. 7. 7. 3. 5. 7. 5. 6. 6. 6. 5. 6. 7. 5. 6. 6. 5. 6. 6. 5. 5. 6. 6.\n",
      " 6. 5. 6. 5. 6. 8. 5. 5. 5. 6. 6. 5. 6. 5. 5. 5. 5. 5. 4. 5. 5. 6. 5. 4.\n",
      " 7. 5. 6. 5. 6. 5. 5. 5. 5. 5. 6. 5. 5. 5. 5. 5. 6. 5. 5. 4. 5. 5. 6. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 6. 6. 5. 5. 5. 5. 5. 5. 6. 6. 6. 5. 6. 6. 6. 5.\n",
      " 5. 7. 7. 5. 7. 7. 5. 7. 5. 4. 5. 5. 7. 7. 5. 4. 7. 5. 7. 7. 7. 5. 5. 7.\n",
      " 7. 7. 4. 7. 6. 6. 6. 5. 5. 6. 7. 7. 7. 7. 6. 7. 6. 6. 6. 7. 5. 7. 5. 7.\n",
      " 6. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 6. 5. 7. 5. 5. 7. 5.]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'sum' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     yhat[loop]\u001b[39m=\u001b[39mlocateMax(predictions[loop])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb#W3sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(yhat)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m train_error \u001b[39m=\u001b[39m accuracy(yhat,y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb#W3sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m nn_train_error\u001b[39m.\u001b[39mappend(train_error)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# Record the fraction of misclassified examples for the cross validation set\u001b[39;00m\n",
      "\u001b[1;32m/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb Cell 9\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(y, yp)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m loop \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m(yp[loop] \u001b[39m==\u001b[39m y[loop]):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39msum\u001b[39m\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/henri/ZZZ2/wineQualityPrediction/8NNSoftMaxCrossValidation.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mreturn\u001b[39;00m((\u001b[39msum\u001b[39m\u001b[39m/\u001b[39mm)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'sum' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Initialize lists that will contain the errors for each model\n",
    "nn_train_error = []\n",
    "nn_cv_error = []\n",
    "\n",
    "\n",
    "# Build the models\n",
    "nn_models = build_models()\n",
    "\n",
    "# Loop over the the models\n",
    "for model in nn_models:\n",
    "    \n",
    "    # Setup the loss and optimizer\n",
    "    model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    )\n",
    "\n",
    "    print(f\"Training {model.name}...\")\n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(\"Done!\\n\")\n",
    "\n",
    "    # Set the threshold for classification\n",
    "    threshold = 0.5\n",
    "    # Record the fraction of misclassified examples for the training set\n",
    "    predictions = model.predict(X_train)\n",
    "    yhat= np.zeros(len(predictions))\n",
    "\n",
    "    for loop in range(len(predictions)):\n",
    "        yhat[loop]=locateMax(predictions[loop])\n",
    "    print(yhat)\n",
    "\n",
    "    train_error = accuracy(yhat,y_train)\n",
    "    nn_train_error.append(train_error)\n",
    "\n",
    "    # Record the fraction of misclassified examples for the cross validation set\n",
    "    predictions = model.predict(X_cv)\n",
    "    yhat= np.zeros(len(predictions))\n",
    "\n",
    "    for loop in range(len(predictions)):\n",
    "        yhat[loop]=locateMax(predictions[loop])\n",
    "    print(yhat)\n",
    "\n",
    "    cv_error = accuracy(yhat,y_cv)\n",
    "    nn_cv_error.append(cv_error)\n",
    "\n",
    "    \n",
    "# Print the result\n",
    "for model_num in range(len(nn_train_error)):\n",
    "    print(\n",
    "        f\"Model {model_num+1}: Training Set Classification Error: {nn_train_error[model_num]:.5f}, \" +\n",
    "        f\"CV Set Classification Error: {nn_cv_error[model_num]:.5f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "Selected Model: 3\n",
      "Training MSE: 11.74\n",
      "Cross Validation MSE: 13.65\n",
      "Test MSE: 11.08\n"
     ]
    }
   ],
   "source": [
    "# Select the model with the lowest CV MSE\n",
    "model_num = 3\n",
    "\n",
    "# Compute the test MSE\n",
    "predict = model.predict(X_cv)\n",
    "yhat=tf.nn.softmax(predict).numpy()\n",
    "test_mse = mean_squared_error(y_test, yhat) / 2\n",
    "\n",
    "print(f\"Selected Model: {model_num}\")\n",
    "print(f\"Training MSE: {nn_train_mses[model_num-1]:.2f}\")\n",
    "print(f\"Cross Validation MSE: {nn_cv_mses[model_num-1]:.2f}\")\n",
    "print(f\"Test MSE: {test_mse:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALISATION TEST DU MODELE CHOISI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_plot=np.array(X_test)\n",
    "y_plot=np.array(y_test).reshape(-1,1)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "m = X_test.shape[0]\n",
    "\n",
    "predictions = nn_models[model_num-1].predict(X_test)\n",
    "for loop in range(len(predictions)):\n",
    "    yp_all[loop]=locateMax(predictions[loop])\n",
    "\n",
    "    # plot predictions and targets versus original features    \n",
    "fig,ax=plt.subplots(1,4,figsize=(12, 3),sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter([x_all[:,i]],y_all, label = 'target')\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "    ax[i].scatter([x_all[:,i]],yp_all,color=\"orange\", label = 'predict')\n",
    "ax[0].set_ylabel(\"Quality\"); ax[0].legend()\n",
    "fig.suptitle(\"target versus prediction using Softmax model\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
