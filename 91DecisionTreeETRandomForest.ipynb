{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1, 1, 1,1],\n",
    "[0, 0, 1,1],\n",
    " [0, 1, 0,1],\n",
    " [1, 0, 1,1],\n",
    " [1, 1, 1,1],\n",
    " [1, 1, 0,1],\n",
    " [0, 0, 0,1],\n",
    " [1, 1, 0,1],\n",
    " [0, 1, 0,1],\n",
    " [0, 1, 0,1]])\n",
    "\n",
    "y_train = np.array([1, 1, 0, 0, 1, 1, 0, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def entropy(p):\n",
    "    if p == 0 or p == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return -p * np.log2(p) - (1- p)*np.log2(1 - p)\n",
    "    \n",
    "print(entropy(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(X, index_feature):\n",
    "    \"\"\"Given a dataset and a index feature, return two lists for the two split nodes, the left node has the animals that have \n",
    "    that feature = 1 and the right node those that have the feature = 0 \n",
    "    index feature = 0 => ear shape\n",
    "    index feature = 1 => face shape\n",
    "    index feature = 2 => whiskers\n",
    "    \"\"\"\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "    for i,x in enumerate(X):\n",
    "        if x[index_feature] == 1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "    return left_indices, right_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 3, 4, 5, 7], [1, 2, 6, 8, 9])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_indices(X_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_entropy(X,y,left_indices,right_indices):\n",
    "    \"\"\"\n",
    "    This function takes the splitted dataset, the indices we chose to split and returns the weighted entropy.\n",
    "    \"\"\"\n",
    "    w_left = len(left_indices)/len(X)\n",
    "    w_right = len(right_indices)/len(X)\n",
    "    p_left = sum(y[left_indices])/len(left_indices)\n",
    "    p_right = sum(y[right_indices])/len(right_indices)\n",
    "    \n",
    "    weighted_entropy = w_left * entropy(p_left) + w_right * entropy(p_right)\n",
    "    return weighted_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7219280948873623"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_indices, right_indices = split_indices(X_train, 0)\n",
    "weighted_entropy(X_train, y_train, left_indices, right_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(X, y, left_indices, right_indices):\n",
    "    \"\"\"\n",
    "    Here, X has the elements in the node and y is theirs respectives classes\n",
    "    \"\"\"\n",
    "    p_node = sum(y)/len(y)\n",
    "    h_node = entropy(p_node)\n",
    "    w_entropy = weighted_entropy(X,y,left_indices,right_indices)\n",
    "    return h_node - w_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2780719051126377"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain(X_train, y_train, left_indices, right_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Ear Shape, information gain if we split the root node using this feature: 0.28\n",
      "Feature: Face Shape, information gain if we split the root node using this feature: 0.03\n",
      "Feature: Whiskers, information gain if we split the root node using this feature: 0.12\n"
     ]
    }
   ],
   "source": [
    "for i, feature_name in enumerate(['Ear Shape', 'Face Shape', 'Whiskers']):\n",
    "    left_indices, right_indices = split_indices(X_train, i)\n",
    "    i_gain = information_gain(X_train, y_train, left_indices, right_indices)\n",
    "    print(f\"Feature: {feature_name}, information gain if we split the root node using this feature: {i_gain:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(y):\n",
    "\n",
    "    entropy = 0\n",
    "    \n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    entropy = sum(y[y==1])/len(y)\n",
    "    if entropy == 0 or entropy == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return -entropy*np.log2(entropy) - (1-entropy)*np.log2(1-entropy)\n",
    "     \n",
    "\n",
    "def split_dataset(X, node_indices, feature):\n",
    "\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "\n",
    "    for i in node_indices:\n",
    "        if X[i][feature] == 1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "        \n",
    "    return left_indices, right_indices \n",
    "def compute_information_gain(X, y, node_indices, feature):\n",
    "    \n",
    "    left_indices, right_indices = split_dataset(X, node_indices, feature)\n",
    "    \n",
    "    X_node, y_node = X[node_indices], y[node_indices]\n",
    "    X_left, y_left = X[left_indices], y[left_indices]\n",
    "    X_right, y_right = X[right_indices], y[right_indices]\n",
    "    \n",
    "    information_gain = 0\n",
    "    \n",
    "    node_entropy = compute_entropy(y_node)\n",
    "    left_entropy = compute_entropy(y_left)\n",
    "    right_entropy = compute_entropy(y_right)\n",
    "    w_left = len(X_left) / len(X_node)\n",
    "    w_right = len(X_right) / len(X_node)\n",
    "    weighted_entropy = w_left * left_entropy + w_right * right_entropy\n",
    "    information_gain = node_entropy - weighted_entropy\n",
    "    \n",
    "    return information_gain\n",
    "def get_best_split(X, y, node_indices):   \n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "    best_feature = -1\n",
    "\n",
    "    max_info_gain = 0\n",
    "    for feature in range(num_features):\n",
    "        info_gain = compute_information_gain(X, y, node_indices, feature)\n",
    "        if info_gain > max_info_gain:\n",
    "            max_info_gain = info_gain\n",
    "            best_feature = feature\n",
    "    print(\"max_info_gain\",max_info_gain)\n",
    "   \n",
    "    return best_feature\n",
    "def build_tree_recursive(X, y, node_indices, branch_name, max_depth, current_depth, tree):\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        formatting = \" \"*current_depth + \"-\"*current_depth\n",
    "        print(formatting, \"%s leaf node with indices\" % branch_name, node_indices)\n",
    "        return\n",
    "   \n",
    "\n",
    "    best_feature = get_best_split(X, y, node_indices) \n",
    "    \n",
    "    formatting = \"-\"*current_depth\n",
    "    print(\"%s Depth %d, %s: Split on feature: %d\" % (formatting, current_depth, branch_name, best_feature))\n",
    "    \n",
    "\n",
    "    left_indices, right_indices = split_dataset(X, node_indices, best_feature)\n",
    "    tree.append((left_indices, right_indices, best_feature))\n",
    "    \n",
    "    build_tree_recursive(X, y, left_indices, \"Left\", max_depth, current_depth+1, tree)\n",
    "    build_tree_recursive(X, y, right_indices, \"Right\", max_depth, current_depth+1, tree)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Depth 0, Root: Split on feature: 0\n",
      " - Left leaf node with indices [0, 3, 4, 5, 7]\n",
      " - Right leaf node with indices [1, 2, 6, 8, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([0, 3, 4, 5, 7], [1, 2, 6, 8, 9], 0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = []\n",
    "build_tree_recursive(X_train, y_train, [0,1,2,3,4,5,6,7,8,9], \"Root\", max_depth=1, current_depth=0, tree = tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_info_gain 0.2780719051126377\n",
      " Depth 0, Root: Split on feature: 0\n",
      "max_info_gain 0.7219280948873623\n",
      "- Depth 1, Left: Split on feature: 1\n",
      "max_info_gain 0\n",
      "-- Depth 2, Left: Split on feature: -1\n",
      "   --- Left leaf node with indices [0, 4, 5, 7]\n",
      "   --- Right leaf node with indices []\n",
      "max_info_gain 0\n",
      "-- Depth 2, Right: Split on feature: -1\n",
      "   --- Left leaf node with indices [3]\n",
      "   --- Right leaf node with indices []\n",
      "max_info_gain 0.7219280948873623\n",
      "- Depth 1, Right: Split on feature: 2\n",
      "max_info_gain 0\n",
      "-- Depth 2, Left: Split on feature: -1\n",
      "   --- Left leaf node with indices [1]\n",
      "   --- Right leaf node with indices []\n",
      "max_info_gain 0\n",
      "-- Depth 2, Right: Split on feature: -1\n",
      "   --- Left leaf node with indices [2, 6, 8, 9]\n",
      "   --- Right leaf node with indices []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([0, 3, 4, 5, 7], [1, 2, 6, 8, 9], 0),\n",
       " ([0, 4, 5, 7], [3], 1),\n",
       " ([0, 4, 5, 7], [], -1),\n",
       " ([3], [], -1),\n",
       " ([1], [2, 6, 8, 9], 2),\n",
       " ([1], [], -1),\n",
       " ([2, 6, 8, 9], [], -1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = []\n",
    "build_tree_recursive(X_train, y_train, [0,1,2,3,4,5,6,7,8,9], \"Root\", max_depth=3, current_depth=0, tree = tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TREE ENSEMBLES : RANDOM FOREST POUR LA QUALITE DU VIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "\n",
    "RANDOM_STATE = 55 ## We will pass it to every sklearn call so we ensure reproducibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prep données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n",
      "0               7.4             0.700         0.00             1.9      0.076  \\\n",
      "1               7.8             0.880         0.00             2.6      0.098   \n",
      "2               7.8             0.760         0.04             2.3      0.092   \n",
      "3              11.2             0.280         0.56             1.9      0.075   \n",
      "4               7.4             0.700         0.00             1.9      0.076   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "1138            6.3             0.510         0.13             2.3      0.076   \n",
      "1139            6.8             0.620         0.08             1.9      0.068   \n",
      "1140            6.2             0.600         0.08             2.0      0.090   \n",
      "1141            5.9             0.550         0.10             2.2      0.062   \n",
      "1142            5.9             0.645         0.12             2.0      0.075   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates   \n",
      "0                    11.0                  34.0  0.99780  3.51       0.56  \\\n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
      "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
      "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
      "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
      "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
      "\n",
      "      alcohol  quality    Id  \n",
      "0         9.4        5     0  \n",
      "1         9.8        5     1  \n",
      "2         9.8        5     2  \n",
      "3         9.8        6     3  \n",
      "4         9.4        5     4  \n",
      "...       ...      ...   ...  \n",
      "1138     11.0        6  1592  \n",
      "1139      9.5        6  1593  \n",
      "1140     10.5        5  1594  \n",
      "1141     11.2        6  1595  \n",
      "1142     10.2        5  1597  \n",
      "\n",
      "[1143 rows x 13 columns]\n",
      "[[ 0.93933222 -0.96338181 -0.57365783 -1.36502663]\n",
      " [ 1.94181282 -0.59360107  0.1308811  -1.36502663]\n",
      " [ 1.27349242 -0.59360107 -0.04525363 -1.16156762]\n",
      " ...\n",
      " [ 0.38239855  0.05351522 -0.45623467 -0.9581086 ]\n",
      " [ 0.10393172  0.70063152  0.60057372 -0.8563791 ]\n",
      " [ 0.6330187  -0.22382033  0.30701583 -0.75464959]]\n",
      "(577,)\n",
      "(577, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('WineQT.csv')\n",
    "print(df)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# load the dataset\n",
    "\n",
    "y_train = df['quality']\n",
    "X_train= [df['volatile acidity'],df['alcohol'],df['sulphates'],df['citric acid']]\n",
    "X_features = ['volatile acidity','alcohol','sulphates','citric acid']\n",
    "X_train=np.transpose(np.asmatrix(X_train))\n",
    "y_train=np.asarray(y_train)\n",
    "\n",
    "\n",
    "def zscore_normalize_features(X):\n",
    "    mu     = np.mean(X, axis=0)                 # mu will have shape (n,)\n",
    "    # find the standard deviation of each column/feature\n",
    "    sigma  = np.std(X, axis=0)                  # sigma will have shape (n,)\n",
    "    # element-wise, subtract mu for that column from each example, divide by std for that column\n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return (X_norm, mu, sigma)\n",
    "\n",
    "X_norm, X_mu, X_sigma = zscore_normalize_features(X_train)\n",
    "print(X_norm)\n",
    "import random\n",
    "fig,ax=plt.subplots(1,2,sharey=True)\n",
    "ax[0].hist(df[\"quality\"], bins='auto',label=\"quality\")\n",
    "ax[0].set_title(\"quality before modif\")\n",
    "supp=[]\n",
    "#on supprime aleatoirement des valeurs de notes 5 et 6 (diviser par 3)\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]==5 or y_train[i]==6:\n",
    "        rand=random.random()\n",
    "        if(rand>0.4):\n",
    "            supp.append(i)\n",
    "for j in range(len(supp)):\n",
    "    y_train2=np.delete(y_train,supp)\n",
    "    X_norm2=np.delete(X_norm,supp,0)\n",
    "\n",
    "\n",
    "ax[1].hist(y_train2, bins='auto',label=\"quality\")\n",
    "ax[1].set_title(\"quality after modif\")\n",
    "\n",
    "print(y_train2.shape)\n",
    "print(X_norm2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n",
      "[5 7 7 5 5 5 7 6 5 6 5 7 4 4 5 5 5 5 5 4 5 6 5 4 4 5 6 5 5 5 5 5 5 7 5 5 6\n",
      " 5 6 4 5 5 4 6 5 5 5 4 4 6 5 5 5 5 6 5 5 5 4 7 6 7 7 5 6 5 5 5 5 6 7 6 6 6\n",
      " 7 7 6 5 6 5 7 5 4 5 5 4 8 6 6 6 8 7 7 7 6 7 5 7 6 6 6 5 6 7 5 6 6 7 5 5 7\n",
      " 7 5 7 6 6 6 6 6 7 7 6 5 7 7 5 7 6 6 6 7 6 6 8 7 5 5 6 5 7 4 7 5 5 6 6 7 5\n",
      " 7 7 6 6 7 5 5 6 6 5 8 7 7 5 6 7 8 5 3 6 6 5 5 6 8 5 6 7 7 6 8 5 8 7 7 7 7\n",
      " 7 7 7 7 5 3 5 6 5 5 7 5 5 6 5 6 6 6 5 5 6 5 5 6 6 6 6 4 5 7 8 6 5 6 6 5 5\n",
      " 5 5 6 6 4 5 5 5 4 7 7 5 5 6 6 5 6 5 5 5 5 5 5 5 6 6 4 4 5 6 5 5 5 6 6 5 5\n",
      " 5 6 6 6 5 5 5 6 5 5 5 6 5 5 5 5 6 5 6 6 5 5 7 5 7 6 7 5 6 5 4 5 7 7 4 6 4\n",
      " 7 7 7 5 6 5 6 6 7 7 5 4 7 6 6 5 5 6 7 6 7 5 7 7 7 5 6 6 6 6 5 6 7 4 5 7 5\n",
      " 6 5 7 7 7 7 7 7 7 7 7 7 5 7 5 6 7 7 5 5 5 6 6 7 5 7 7 7 7 7 6 7 5 6 5 6 7\n",
      " 6 7 7 7 7 6 6 6 5 5 5 7 6 7 5 7 7 8 6 7 7 5 7 6 7 7 7 7 7 8 7 6 6 7 6 6 7\n",
      " 6 6 6 8 7 5 7 7 7 6 6 6 6 6 5 7 6 6 5 5 7 7 7 5 7 6 6 6 6 4 5 5 4 7 6 7 8\n",
      " 7 7 7 7 6 6 5 7 6 4 4 6 5 5 5 5 5 4 5 6 6 6 6 4 6 7 6 5 5 5 6 3 5 5 5 5 6\n",
      " 6 6 6 6 5 6 5 5 6 6 5 5 6 5 6 6 6 6 6 6 5 8 7 6 6 5 5 7 5 5 5 4 5 5 5 7 6\n",
      " 5 5 8 7 7 7 6 6 5 5 7 4 7 4 7 3 6 5 7 7 3 4 5 5 5 7 6 5 3 6 5 6 6 6 5 5 5\n",
      " 5 5 6 7 6 7 6 8 5 7 6 5 5 6 5 6 6 6 5 7 6 6]\n",
      "[2 4 4 2 2 2 4 3 2 3 2 4 1 1 2 2 2 2 2 1 2 3 2 1 1 2 3 2 2 2 2 2 2 4 2 2 3\n",
      " 2 3 1 2 2 1 3 2 2 2 1 1 3 2 2 2 2 3 2 2 2 1 4 3 4 4 2 3 2 2 2 2 3 4 3 3 3\n",
      " 4 4 3 2 3 2 4 2 1 2 2 1 5 3 3 3 5 4 4 4 3 4 2 4 3 3 3 2 3 4 2 3 3 4 2 2 4\n",
      " 4 2 4 3 3 3 3 3 4 4 3 2 4 4 2 4 3 3 3 4 3 3 5 4 2 2 3 2 4 1 4 2 2 3 3 4 2\n",
      " 4 4 3 3 4 2 2 3 3 2 5 4 4 2 3 4 5 2 0 3 3 2 2 3 5 2 3 4 4 3 5 2 5 4 4 4 4\n",
      " 4 4 4 4 2 0 2 3 2 2 4 2 2 3 2 3 3 3 2 2 3 2 2 3 3 3 3 1 2 4 5 3 2 3 3 2 2\n",
      " 2 2 3 3 1 2 2 2 1 4 4 2 2 3 3 2 3 2 2 2 2 2 2 2 3 3 1 1 2 3 2 2 2 3 3 2 2\n",
      " 2 3 3 3 2 2 2 3 2 2 2 3 2 2 2 2 3 2 3 3 2 2 4 2 4 3 4 2 3 2 1 2 4 4 1 3 1\n",
      " 4 4 4 2 3 2 3 3 4 4 2 1 4 3 3 2 2 3 4 3 4 2 4 4 4 2 3 3 3 3 2 3 4 1 2 4 2\n",
      " 3 2 4 4 4 4 4 4 4 4 4 4 2 4 2 3 4 4 2 2 2 3 3 4 2 4 4 4 4 4 3 4 2 3 2 3 4\n",
      " 3 4 4 4 4 3 3 3 2 2 2 4 3 4 2 4 4 5 3 4 4 2 4 3 4 4 4 4 4 5 4 3 3 4 3 3 4\n",
      " 3 3 3 5 4 2 4 4 4 3 3 3 3 3 2 4 3 3 2 2 4 4 4 2 4 3 3 3 3 1 2 2 1 4 3 4 5\n",
      " 4 4 4 4 3 3 2 4 3 1 1 3 2 2 2 2 2 1 2 3 3 3 3 1 3 4 3 2 2 2 3 0 2 2 2 2 3\n",
      " 3 3 3 3 2 3 2 2 3 3 2 2 3 2 3 3 3 3 3 3 2 5 4 3 3 2 2 4 2 2 2 1 2 2 2 4 3\n",
      " 2 2 5 4 4 4 3 3 2 2 4 1 4 1 4 0 3 2 4 4 0 1 2 2 2 4 3 2 0 3 2 3 3 3 2 2 2\n",
      " 2 2 3 4 3 4 3 5 2 4 3 2 2 3 2 3 3 3 2 4 3 3]\n"
     ]
    }
   ],
   "source": [
    "X_train=X_norm2\n",
    "y_train=y_train2\n",
    "n = int(len(X_train)*0.8) ## Let's use 80% to train and 20% to eval\n",
    "print(int(len(y_train)*0.8)) ## Let's use 80% to train and 20% to eval\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "print(y_train)\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fit, X_train_eval, y_train_fit, y_train_eval = X_train[:n], X_train[n:], y_train[:n], y_train[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henri/.local/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.71736\n",
      "[1]\tvalidation_0-mlogloss:1.65396\n",
      "[2]\tvalidation_0-mlogloss:1.60354\n",
      "[3]\tvalidation_0-mlogloss:1.56349\n",
      "[4]\tvalidation_0-mlogloss:1.52903\n",
      "[5]\tvalidation_0-mlogloss:1.50038\n",
      "[6]\tvalidation_0-mlogloss:1.47499\n",
      "[7]\tvalidation_0-mlogloss:1.45421\n",
      "[8]\tvalidation_0-mlogloss:1.43997\n",
      "[9]\tvalidation_0-mlogloss:1.42367\n",
      "[10]\tvalidation_0-mlogloss:1.41295\n",
      "[11]\tvalidation_0-mlogloss:1.39892\n",
      "[12]\tvalidation_0-mlogloss:1.38823\n",
      "[13]\tvalidation_0-mlogloss:1.37961\n",
      "[14]\tvalidation_0-mlogloss:1.37412\n",
      "[15]\tvalidation_0-mlogloss:1.37080\n",
      "[16]\tvalidation_0-mlogloss:1.36956\n",
      "[17]\tvalidation_0-mlogloss:1.36724\n",
      "[18]\tvalidation_0-mlogloss:1.36344\n",
      "[19]\tvalidation_0-mlogloss:1.35937\n",
      "[20]\tvalidation_0-mlogloss:1.35705\n",
      "[21]\tvalidation_0-mlogloss:1.35549\n",
      "[22]\tvalidation_0-mlogloss:1.35438\n",
      "[23]\tvalidation_0-mlogloss:1.35433\n",
      "[24]\tvalidation_0-mlogloss:1.35589\n",
      "[25]\tvalidation_0-mlogloss:1.35737\n",
      "[26]\tvalidation_0-mlogloss:1.35711\n",
      "[27]\tvalidation_0-mlogloss:1.35809\n",
      "[28]\tvalidation_0-mlogloss:1.35976\n",
      "[29]\tvalidation_0-mlogloss:1.36219\n",
      "[30]\tvalidation_0-mlogloss:1.36135\n",
      "[31]\tvalidation_0-mlogloss:1.36563\n",
      "[32]\tvalidation_0-mlogloss:1.36893\n",
      "[33]\tvalidation_0-mlogloss:1.37079\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(n_estimators = 500, learning_rate = 0.1,verbosity = 1, random_state = RANDOM_STATE)\n",
    "xgb_model.fit(X_train_fit,y_train_fit, eval_set = [(X_train_eval,y_train_eval)], early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics train:\n",
      "\tAccuracy score: 0.7695\n",
      "Metrics test:\n",
      "\tAccuracy score: 0.7695\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metrics train:\\n\\tAccuracy score: {accuracy_score(xgb_model.predict(X_train),y_train):.4f}\\nMetrics test:\\n\\tAccuracy score: {accuracy_score(xgb_model.predict(X_train),y_train):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
